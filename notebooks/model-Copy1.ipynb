{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import seaborn_image as isns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comnist_data = np.loadtxt('./../datasets/latin_data.csv', delimiter=\",\", dtype=\"float32\")\n",
    "comnist_label = np.loadtxt('./../datasets/latin_label.csv', delimiter=\",\", dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "i = np.random.randint(comnist_data.shape[0])\n",
    "my_letter = np.flip(comnist_data[i].reshape(28, 28), 0)\n",
    "my_label = string.ascii_uppercase[int(comnist_label[i])]\n",
    "print(f\"Displaying letter {my_label}\")\n",
    "isns.imgplot(my_letter, cmap=\"gray\", describe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "class Ð¡oMNISTDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        labels_dir,\n",
    "        data_dir,\n",
    "        transform=None,\n",
    "        target_transform=None\n",
    "    ):\n",
    "        self.img_labels = pd.read_csv(labels_dir)\n",
    "        self.img_features = pd.read_csv(data_dir)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.asarray(self.img_features.iloc[idx], dtype=np.float32).reshape(28,28)\n",
    "        label = self.img_labels.iloc[idx, 0]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training_samples: 128\n",
      "validation_samples: 12693\n",
      "\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comnnist_dataset = Ð¡oMNISTDataset(\n",
    "    labels_dir='./../datasets/latin_label.csv',\n",
    "    data_dir='./../datasets/latin_data.csv',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.functional.vflip,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=0.0942,\n",
    "                             std=0.2352)\n",
    "    ])\n",
    ")\n",
    "training_samples = int(len(comnnist_dataset) * 0.01)\n",
    "validation_samples = len(comnnist_dataset) - training_samples\n",
    "print(f'''\n",
    "training_samples: {training_samples}\n",
    "validation_samples: {validation_samples}\n",
    "''')\n",
    "\n",
    "isns.imshow(comnnist_dataset[100][0].squeeze(0))\n",
    "print(comnnist_dataset[100][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = comnnist_dataset[100][0]\n",
    "plt.imshow(image.permute(1, 2 ,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in comnnist_dataset], dim=3)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imgs.view(1, -1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imgs.view(1, -1).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(\n",
    "    comnnist_dataset,\n",
    "    [training_samples, validation_samples],\n",
    "    generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_i = iter(train_loader)\n",
    "images, labels = data_i.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20 / 2, idx + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    # print out the correct label for each image\n",
    "    # .item() gets the value contained in a Tensor\n",
    "    ax.set_title(string.ascii_uppercase[int(labels[idx].item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = np.squeeze(images[0])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "width, height = img.shape\n",
    "thresh = img.max() / 2.5\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        val = round(img[x][y], 2) if img[x][y] != 0 else 0\n",
    "        ax.annotate(str(val), xy=(y, x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    color='white' if img[x][y] < thresh else 'black')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_out=26):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 26, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img, _ = comnnist_dataset[0]\n",
    "img_batch = img.unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "isns.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0093,  0.0042, -0.0103,  0.0030, -0.0287, -0.0125,  0.0075, -0.0174,\n",
       "         -0.0064,  0.0152,  0.0158, -0.0058,  0.0084, -0.0046, -0.0107, -0.0262,\n",
       "         -0.0073,  0.0009, -0.0189,  0.0001, -0.0042, -0.0100, -0.0089,  0.0069,\n",
       "         -0.0145, -0.0085]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = AlexNet()\n",
    "out = alexnet(img.unsqueeze(0))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "out = model(img.unsqueeze(0))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Specify loss and optimization functions\n",
    "\n",
    "# specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.Adam(alexnet.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-1e30c4003741>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\minicondaenv\\main\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\minicondaenv\\main\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "\n",
    "alexnet.train()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss_train = 0.0\n",
    "    # loss_val = 0.0\n",
    "    # correct = 0\n",
    "    # total = 0\n",
    "    for images, labels in train_loader:\n",
    "        outputs = alexnet(images)\n",
    "        train_loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += train_loss.item()\n",
    "\n",
    "    print(f'{datetime.datetime.now()} Epoch {epoch}, Training loss {loss_train / len(train_loader)}')\n",
    "    # with torch.no_grad():\n",
    "    #     for images, labels in val_loader:\n",
    "    #         outputs = alexnet(images)\n",
    "    #         val_loss = loss_fn(outputs, labels)\n",
    "    #         _, predicted = torch.max(outputs, dim=1)\n",
    "    #         total += labels.shape[0]\n",
    "    #         correct += int((predicted == labels).sum())\n",
    "    #         loss_val += val_loss.item()\n",
    "\n",
    "    # if epoch == 1 or epoch % 5 == 0:\n",
    "    #     print(f'{datetime.datetime.now()} Epoch {epoch}, Training loss {loss_train / len(train_loader)}')\n",
    "          #f', Validation loss {loss_val / len(val_loader)}, Accuracy {correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(dict(epoch=epoch_list, loss=train_loss_list))\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "fig = sns.relplot(\n",
    "    x='epoch'\n",
    "    , y='loss'\n",
    "    , kind='scatter'\n",
    "    , data=data\n",
    ")\n",
    "fig.savefig(\"output_3_80_relu.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# obtain one batch of test images\n",
    "dataiter = iter(val_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# convert output probabilities to predicted class\n",
    "_, preds = torch.max(output, 1)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20 / 2, idx + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(\n",
    "        \"{} ({})\".format(string.ascii_uppercase[int(preds[idx].item())],string.ascii_uppercase[int(labels[idx].item())]),\n",
    "        color=(\"green\" if preds[idx] == labels[idx] else \"red\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.zeros(1).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()  # prep model for *evaluation*\n",
    "\n",
    "for data, target in test_loader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss\n",
    "    test_loss += loss.item() * data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(100):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)')\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
